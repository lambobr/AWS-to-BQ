[2022-12-15T05:51:28.827+0000] {processor.py:154} INFO - Started process (PID=43) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:51:28.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:51:28.830+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:51:28.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:51:28.858+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:51:28.856+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:51:28.858+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:51:28.893+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.071 seconds
[2022-12-15T05:51:59.213+0000] {processor.py:154} INFO - Started process (PID=95) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:51:59.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:51:59.214+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:51:59.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:51:59.220+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:51:59.219+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:51:59.220+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:51:59.240+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.029 seconds
[2022-12-15T05:52:30.085+0000] {processor.py:154} INFO - Started process (PID=154) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:52:30.086+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:52:30.086+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:52:30.086+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:52:30.209+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:52:30.208+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:52:30.209+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:52:30.227+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.144 seconds
[2022-12-15T05:53:00.281+0000] {processor.py:154} INFO - Started process (PID=213) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:53:00.281+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:53:00.282+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:53:00.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:53:00.289+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:53:00.288+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:53:00.289+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:53:00.307+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.029 seconds
[2022-12-15T05:53:30.666+0000] {processor.py:154} INFO - Started process (PID=264) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:53:30.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:53:30.668+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:53:30.668+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:53:30.682+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:53:30.681+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:53:30.683+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:53:30.722+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.061 seconds
[2022-12-15T05:54:01.156+0000] {processor.py:154} INFO - Started process (PID=322) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:54:01.157+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:54:01.157+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:54:01.157+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:54:01.171+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:54:01.170+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:54:01.172+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:54:01.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.038 seconds
[2022-12-15T05:54:31.536+0000] {processor.py:154} INFO - Started process (PID=380) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:54:31.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:54:31.537+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:54:31.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:54:31.545+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:54:31.544+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:54:31.545+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:54:31.564+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.030 seconds
[2022-12-15T05:55:01.975+0000] {processor.py:154} INFO - Started process (PID=431) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:55:01.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:55:01.976+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:55:01.976+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:55:01.984+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:55:01.983+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:55:01.985+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:55:02.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.039 seconds
[2022-12-15T05:55:32.249+0000] {processor.py:154} INFO - Started process (PID=490) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:55:32.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:55:32.251+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:55:32.250+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:55:32.257+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:55:32.256+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:55:32.257+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:55:32.273+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.026 seconds
[2022-12-15T05:56:26.234+0000] {processor.py:154} INFO - Started process (PID=41) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:56:26.236+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:56:26.236+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:56:26.236+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:56:26.250+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:56:26.248+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:56:26.250+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:56:26.271+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.040 seconds
[2022-12-15T05:56:56.727+0000] {processor.py:154} INFO - Started process (PID=92) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:56:56.728+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:56:56.729+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:56:56.728+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:56:56.737+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:56:56.736+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:56:56.737+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:56:56.759+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.034 seconds
[2022-12-15T05:57:27.737+0000] {processor.py:154} INFO - Started process (PID=151) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:57:27.738+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:57:27.738+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:57:27.738+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:57:27.746+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:57:27.745+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:57:27.747+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:57:27.772+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.037 seconds
[2022-12-15T05:57:57.843+0000] {processor.py:154} INFO - Started process (PID=210) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:57:57.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:57:57.846+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:57:57.846+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:57:57.861+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:57:57.859+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:57:57.861+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:57:58.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.210 seconds
[2022-12-15T05:59:36.668+0000] {processor.py:154} INFO - Started process (PID=41) to work on /opt/airflow/dags/dags.py
[2022-12-15T05:59:36.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T05:59:36.671+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:59:36.671+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T05:59:36.693+0000] {logging_mixin.py:137} INFO - [2022-12-15T05:59:36.691+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T05:59:36.694+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T05:59:36.723+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.060 seconds
[2022-12-15T06:00:07.135+0000] {processor.py:154} INFO - Started process (PID=92) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:00:07.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:00:07.136+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:00:07.136+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:00:07.145+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:00:07.144+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T06:00:07.145+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:00:07.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.031 seconds
[2022-12-15T06:00:37.602+0000] {processor.py:154} INFO - Started process (PID=151) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:00:37.603+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:00:37.604+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:00:37.604+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:00:37.612+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:00:37.611+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T06:00:37.612+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:00:37.632+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.034 seconds
[2022-12-15T06:01:08.559+0000] {processor.py:154} INFO - Started process (PID=210) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:01:08.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:01:08.560+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:01:08.560+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:01:08.567+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:01:08.566+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T06:01:08.567+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:01:08.584+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.028 seconds
[2022-12-15T06:01:38.885+0000] {processor.py:154} INFO - Started process (PID=261) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:01:38.887+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:01:38.887+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:01:38.887+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:01:38.894+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:01:38.893+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/dags.py", line 22, in <module>
    load = BashOperator(task_id="extract", bash_command="python3 /opt/airflow/python_scripts/bq_data_transfer.py")
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 774, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/task_group.py", line 212, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract' has already been added to the DAG
[2022-12-15T06:01:38.894+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:01:38.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.032 seconds
[2022-12-15T06:04:08.925+0000] {processor.py:154} INFO - Started process (PID=41) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:04:08.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:04:08.926+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:04:08.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:04:08.969+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:04:09.194+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:04:09.194+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:04:09.223+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:04:09.223+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:04:09.223297+00:00, run_after=2022-12-15T06:04:09.223297+00:00
[2022-12-15T06:04:09.256+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.334 seconds
[2022-12-15T06:04:39.372+0000] {processor.py:154} INFO - Started process (PID=57) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:04:39.372+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:04:39.373+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:04:39.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:04:39.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:04:39.533+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:04:39.533+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:04:39.552+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:04:39.552+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:04:39.552137+00:00, run_after=2022-12-15T06:04:39.552137+00:00
[2022-12-15T06:04:39.569+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.199 seconds
[2022-12-15T06:05:09.677+0000] {processor.py:154} INFO - Started process (PID=79) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:05:09.678+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:05:09.678+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:05:09.678+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:05:09.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:05:09.859+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:05:09.859+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:05:09.880+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:05:09.880+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:05:09.880123+00:00, run_after=2022-12-15T06:05:09.880123+00:00
[2022-12-15T06:05:09.897+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.222 seconds
[2022-12-15T06:05:40.101+0000] {processor.py:154} INFO - Started process (PID=101) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:05:40.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:05:40.102+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:05:40.102+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:05:40.116+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:05:40.149+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:05:40.148+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:05:40.167+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:05:40.167+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:05:40.167284+00:00, run_after=2022-12-15T06:05:40.167284+00:00
[2022-12-15T06:05:40.187+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.089 seconds
[2022-12-15T06:06:10.210+0000] {processor.py:154} INFO - Started process (PID=116) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:06:10.211+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:06:10.211+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:06:10.211+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:06:10.224+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:06:10.261+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:06:10.260+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:06:10.283+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:06:10.283+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:06:10.283288+00:00, run_after=2022-12-15T06:06:10.283288+00:00
[2022-12-15T06:06:10.302+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.095 seconds
[2022-12-15T06:06:40.387+0000] {processor.py:154} INFO - Started process (PID=138) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:06:40.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:06:40.388+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:06:40.388+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:06:40.400+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:06:40.436+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:06:40.436+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:06:40.458+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:06:40.457+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:06:40.457645+00:00, run_after=2022-12-15T06:06:40.457645+00:00
[2022-12-15T06:06:40.479+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.095 seconds
[2022-12-15T06:07:10.507+0000] {processor.py:154} INFO - Started process (PID=160) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:07:10.507+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:07:10.508+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:07:10.508+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:07:10.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:07:10.561+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:07:10.560+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:07:10.585+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:07:10.585+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T00:07:10.585416+00:00, run_after=2022-12-15T06:07:10.585416+00:00
[2022-12-15T06:07:10.611+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.107 seconds
[2022-12-15T06:07:40.695+0000] {processor.py:154} INFO - Started process (PID=175) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:07:40.695+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:07:40.696+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:07:40.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:07:40.707+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:07:40.740+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:07:40.739+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:07:40.757+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:07:40.757+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T06:07:10.585416+00:00, run_after=2022-12-15T12:07:10.585416+00:00
[2022-12-15T06:07:40.776+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.083 seconds
[2022-12-15T06:08:10.815+0000] {processor.py:154} INFO - Started process (PID=197) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:08:10.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:08:10.816+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:08:10.816+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:08:10.827+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:08:10.861+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:08:10.861+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:08:10.883+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:08:10.883+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T06:07:10.585416+00:00, run_after=2022-12-15T12:07:10.585416+00:00
[2022-12-15T06:08:10.906+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.092 seconds
[2022-12-15T06:08:40.975+0000] {processor.py:154} INFO - Started process (PID=212) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:08:40.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:08:40.976+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:08:40.976+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:08:40.987+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:08:41.018+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:08:41.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:08:41.038+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:08:41.037+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T06:07:10.585416+00:00, run_after=2022-12-15T12:07:10.585416+00:00
[2022-12-15T06:08:41.059+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.085 seconds
[2022-12-15T06:09:11.116+0000] {processor.py:154} INFO - Started process (PID=234) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:09:11.116+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:09:11.116+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:09:11.116+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:09:11.128+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:09:11.162+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:09:11.162+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:09:11.182+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:09:11.181+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T06:07:10.585416+00:00, run_after=2022-12-15T12:07:10.585416+00:00
[2022-12-15T06:09:11.204+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.090 seconds
[2022-12-15T06:09:41.270+0000] {processor.py:154} INFO - Started process (PID=256) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:09:41.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:09:41.271+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:09:41.271+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:09:41.282+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:09:41.313+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:09:41.313+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:09:41.332+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:09:41.332+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T06:07:10.585416+00:00, run_after=2022-12-15T12:07:10.585416+00:00
[2022-12-15T06:09:41.348+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.080 seconds
[2022-12-15T06:10:11.420+0000] {processor.py:154} INFO - Started process (PID=271) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:10:11.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:10:11.421+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:10:11.421+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:10:11.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['twitter_etl']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:10:11.463+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:10:11.463+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:10:11.484+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:10:11.484+0000] {dag.py:3336} INFO - Setting next_dagrun for twitter_etl to 2022-12-15T06:07:10.585416+00:00, run_after=2022-12-15T12:07:10.585416+00:00
[2022-12-15T06:10:11.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.082 seconds
[2022-12-15T06:13:18.090+0000] {processor.py:154} INFO - Started process (PID=41) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:13:18.091+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:13:18.092+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:13:18.092+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:13:18.132+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:13:18.313+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:13:18.312+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:13:18.335+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:13:18.335+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T00:13:18.335223+00:00, run_after=2022-12-15T06:13:18.335223+00:00
[2022-12-15T06:13:18.356+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.269 seconds
[2022-12-15T06:13:48.464+0000] {processor.py:154} INFO - Started process (PID=56) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:13:48.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:13:48.465+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:13:48.465+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:13:48.585+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:13:48.621+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:13:48.621+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:13:48.639+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:13:48.639+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T00:13:48.638842+00:00, run_after=2022-12-15T06:13:48.638842+00:00
[2022-12-15T06:13:48.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.194 seconds
[2022-12-15T06:14:18.762+0000] {processor.py:154} INFO - Started process (PID=78) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:14:18.763+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:14:18.763+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:14:18.763+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:14:18.874+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:14:18.903+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:14:18.903+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:14:18.922+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:14:18.922+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T00:14:18.922226+00:00, run_after=2022-12-15T06:14:18.922226+00:00
[2022-12-15T06:14:18.943+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.182 seconds
[2022-12-15T06:14:48.967+0000] {processor.py:154} INFO - Started process (PID=100) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:14:48.987+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:14:48.987+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:14:48.987+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:14:49.004+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:14:49.048+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:14:49.048+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:14:49.075+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:14:49.075+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:14:49.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.137 seconds
[2022-12-15T06:15:19.159+0000] {processor.py:154} INFO - Started process (PID=115) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:15:19.159+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:15:19.160+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:15:19.160+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:15:19.173+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:15:19.208+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:15:19.207+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:15:19.228+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:15:19.228+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:15:19.254+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.098 seconds
[2022-12-15T06:15:49.317+0000] {processor.py:154} INFO - Started process (PID=137) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:15:49.318+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:15:49.318+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:15:49.318+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:15:49.330+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:15:49.366+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:15:49.366+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:15:49.388+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:15:49.388+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:15:49.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.093 seconds
[2022-12-15T06:16:19.470+0000] {processor.py:154} INFO - Started process (PID=152) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:16:19.471+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:16:19.471+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:16:19.471+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:16:19.486+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:16:19.543+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:16:19.543+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:16:19.567+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:16:19.567+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:16:19.589+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.122 seconds
[2022-12-15T06:16:49.618+0000] {processor.py:154} INFO - Started process (PID=174) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:16:49.618+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:16:49.619+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:16:49.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:16:49.632+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:16:49.666+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:16:49.666+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:16:49.690+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:16:49.690+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:16:49.710+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.095 seconds
[2022-12-15T06:17:19.815+0000] {processor.py:154} INFO - Started process (PID=196) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:17:19.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:17:19.817+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:17:19.816+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:17:19.833+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:17:19.872+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:17:19.871+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:17:19.893+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:17:19.893+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:17:19.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.104 seconds
[2022-12-15T06:17:49.930+0000] {processor.py:154} INFO - Started process (PID=211) to work on /opt/airflow/dags/dags.py
[2022-12-15T06:17:49.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/dags.py for tasks to queue
[2022-12-15T06:17:49.931+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:17:49.931+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/dags.py
[2022-12-15T06:17:49.942+0000] {processor.py:766} INFO - DAG(s) dict_keys(['aws_to_bq']) retrieved from /opt/airflow/dags/dags.py
[2022-12-15T06:17:49.972+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:17:49.972+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-15T06:17:49.992+0000] {logging_mixin.py:137} INFO - [2022-12-15T06:17:49.992+0000] {dag.py:3336} INFO - Setting next_dagrun for aws_to_bq to 2022-12-15T06:14:18.922226+00:00, run_after=2022-12-15T12:14:18.922226+00:00
[2022-12-15T06:17:50.016+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/dags.py took 0.088 seconds
